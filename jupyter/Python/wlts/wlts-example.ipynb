{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "informed-version",
   "metadata": {},
   "source": [
    "<img src=\"../../../img/logo-bdc.png\" align=\"right\" width=\"64\"/>\n",
    "\n",
    "# <span style=\"color:#336699\">Web Land Trajectory Service (WLTS) - Example</span>\n",
    "<hr style=\"border:2px solid #0077b9;\">\n",
    "\n",
    "<div style=text-align: left;>\n",
    "    <a href=\"https://nbviewer.jupyter.org/github/brazil-data-cube/code-gallery/blob/master/jupyter/Python/wlts/wlts-introduction.ipynb\"><img src=\"https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg\" align=\"center\"/></a>\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: center;font-size: 90%;\">\n",
    "    Fabiana Zioti<sup><a href=\"https://orcid.org/0000-0002-7305-6043\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>, Felipe Menino Carlos<sup><a href=\"https://orcid.org/0000-0002-3334-4315\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>, Karine Reis Ferreira<sup><a href=\"https://orcid.org/0000-0003-2656-5504\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>, Gilberto R. Queiroz<sup><a href=\"https://orcid.org/0000-0001-7534-0219\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>\n",
    "    <br/><br/>\n",
    "    Earth Observation and Geoinformatics Division, National Institute for Space Research (INPE)\n",
    "    <br/>\n",
    "    Avenida dos Astronautas, 1758, Jardim da Granja, São José dos Campos, SP 12227-010, Brazil\n",
    "    <br/><br/>\n",
    "    Contact: <a href=\"mailto:brazildatacube@inpe.br\">brazildatacube@inpe.br</a>\n",
    "    <br/><br/>\n",
    "    Last Update: March 24, 2021\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: justify;  margin-left: 25%; margin-right: 25%;\">\n",
    "<b>Abstract.</b> In this Jupyter Notebook, an example scenario is presented, which applies the WLTS to extract water bodies samples. The samples are collected using a grid of dots regularly spaced in space. After collecting the samples, they are used for training a linear classifier. Finally, the model is applied to a Remote Sensing image to identify water bodies.\n",
    "\n",
    "This example was created based on the Brazil Data Cube project's approach for selecting samples extracted from WLTS from different projects to classify multiples Brazilian biomes.\n",
    "</div>    \n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: justify;  margin-left: 15%; margin-right: 15%;font-size: 75%; border-style: solid; border-color: #0077b9; border-width: 1px; padding: 5px;\">\n",
    "    <b>This Jupyter Notebook is supplement to the <a href=\"https://www.mdpi.com/2072-4292/12/24/4033/htm#sec5-remotesensing-12-04033\" target=\"_blank\">Section 5</a> of the following paper:</b>\n",
    "    <div style=\"margin-left: 10px; margin-right: 10px; margin-top:10px\">\n",
    "      <p> Ferreira, K.R.; Queiroz, G.R.; Vinhas, L.; Marujo, R.F.B.; Simoes, R.E.O.; Picoli, M.C.A.; Camara, G.; Cartaxo, R.; Gomes, V.C.F.; Santos, L.A.; Sanchez, A.H.; Arcanjo, J.S.; Fronza, J.G.; Noronha, C.A.; Costa, R.W.; Zaglia, M.C.; Zioti, F.; Korting, T.S.; Soares, A.R.; Chaves, M.E.D.; Fonseca, L.M.G. 2020. Earth Observation Data Cubes for Brazil: Requirements, Methodology and Products. Remote Sens. 12, no. 24: 4033. DOI: <a href=\"https://doi.org/10.3390/rs12244033\" target=\"_blank\">10.3390/rs12244033</a>. </p>\n",
    "      <p> Zioti, F.; Gomes, V.C.F.; Ferreira, K.R.; Queiroz, G.R.; Rodriguez, E. L. 2019. Um ambiente para acesso e análise de trajetórias de uso e cobertura da Terra. Anais do XIX Simpósio Brasileiro de Sensoriamento Remoto.São José dos Campos, INPE, 2019. <a href=\"https://proceedings.science/sbsr-2019/papers/um-ambiente-para-acesso-e-analise-de-trajetorias-de-uso-e-cobertura-da-terra\" target=\"_blank\"> Online </a>. </p>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-history",
   "metadata": {},
   "source": [
    "# Python Client API\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-nowhere",
   "metadata": {},
   "source": [
    "For running the examples in this Jupyter Notebook you will need to install the [WLTS client for Python](https://github.com/brazil-data-cube/wlts.py).To install it from PyPI using pip, use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/brazil-data-cube/wlts.py@v0.4.0-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-ranking",
   "metadata": {},
   "source": [
    "We also use the follow library: [numpy](https://numpy.org/), [rasterio](https://rasterio.readthedocs.io/en/latest/), [pandas](https://pandas.pydata.org/), [geopandas](https://geopandas.org/), [seaborn](https://seaborn.pydata.org/), [matplotlib](https://matplotlib.org/), [sklearn](https://scikit-learn.org/stable/). To install those libraries from PyPI using pip, use the following commands:\n",
    "\n",
    "> pip install numpy rasterio pandas geopandas seaborn matplotlib sklearn folium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-produce",
   "metadata": {},
   "source": [
    "# Set the service and load samples\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wlts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-warner",
   "metadata": {},
   "source": [
    "Define the service to be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = wlts.WLTS('https://brazildatacube.dpi.inpe.br/wlts/')\n",
    "service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "service.collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-millennium",
   "metadata": {},
   "source": [
    "**Sampling GRID**\n",
    "\n",
    "To extract the trajectories, use will be made of a sampling grid with equally spaced locations. Below, the grid is loaded using the GeoPandas library.\n",
    "\n",
    ">  The sample points used below were generated using QGIS GIS. If you wish, you can use the [Verde] library (https://www.fatiando.org/verde/latest/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = geopandas.read_file(\"/vsicurl/https://brazildatacube.dpi.inpe.br/public/workshop/bdc-2020-03/wlts/samples/roi_bdc-tile_043042.shp\")\n",
    "samples_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-association",
   "metadata": {},
   "source": [
    "Below, each grid point's spatial location is presented "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# extract sample long, lat\n",
    "#\n",
    "latlon = samples_df.geometry.apply(lambda p: (p.y, p.x)).tolist()\n",
    "\n",
    "#\n",
    "# create folium map\n",
    "#\n",
    "folium_map = folium.Map( location=[-0.52, -51.1526], zoom_start=12)\n",
    "\n",
    "#\n",
    "# Google Satellite Layer\n",
    "#\n",
    "tile = folium.TileLayer(\n",
    "        tiles = \"https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}\",\n",
    "        attr = 'Google',\n",
    "        name = 'Google Satellite',\n",
    "        overlay = False,\n",
    "        control = True\n",
    "       ).add_to(folium_map)\n",
    "\n",
    "#\n",
    "# add marker to map\n",
    "#\n",
    "for coord in latlon:\n",
    "    folium.CircleMarker( location=[ coord[0], coord[1] ], fill_color='#43d9de', radius=3).add_to( folium_map )\n",
    "\n",
    "folium_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-fight",
   "metadata": {},
   "source": [
    "# Retrieving the Trajectory for specific collections\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-great",
   "metadata": {},
   "source": [
    "For this example, the collections `Instituto Brasileiro de Geografia e Estatística (IBGE) - Monitoramento e uso da Terra` and `Projeto de Mapeamento Anual da Cobertura e Uso do Solo no Brasil (MapBiomas) version 5 - Mapa de uso e cobertura da Terra` are used. After collection, the samples are filtered through a concordance analysis. In this analysis, points with compatible classes are used. Other whise, the point is removed.\n",
    "\n",
    "> The trajectories will be extracted separately in the subsections to facilitate their application in the example that will be created, but the [wlts.py] library (https://github.com/brazil-data-cube/wlts.py/) supports the extraction of trajectories considering multiple projects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-saturn",
   "metadata": {},
   "source": [
    "**IBGE - Monitoramento e uso da Terra (2018)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-bookmark",
   "metadata": {},
   "source": [
    "In WLTS, the collection with IBGE data from the Land Use Monitoring project is in the collection named `ibge_land_use_cover`. The code below extracts the trajectory of this collection in the year 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_ibge = []\n",
    "\n",
    "#\n",
    "# Extract trajectory from WLTS\n",
    "#\n",
    "for point_row in samples_df.iterrows():\n",
    "    point_row = point_row[1]\n",
    "    \n",
    "    trajectories_ibge.append(\n",
    "        service.tj(latitude  = point_row.geometry.y, \n",
    "                   longitude = point_row.geometry.x, \n",
    "                   start_date = 2018,\n",
    "                   end_date = 2018,\n",
    "                   collections = \"ibge_cobertura_uso_terra\").df()\n",
    "    )\n",
    "\n",
    "#\n",
    "# Create a Data Frame\n",
    "#\n",
    "trajectories_ibge = pandas.concat(trajectories_ibge).reset_index(drop=True)\n",
    "trajectories_ibge[\"geometry\"] = samples_df[\"geometry\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-optimization",
   "metadata": {},
   "source": [
    "The table below presents the trajectory, with only one year, extracted for all the grid points presented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_ibge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-boston",
   "metadata": {},
   "source": [
    "**MapBiomas version 5 - Mapa de uso e cobertura da Terra**\n",
    "\n",
    "Analogous to the IBGE data, this section extracts the data from MapBiomas. In WLTS, the data from MapBiomas (Version 5) are represented through the collection `mapbiomas5_amazonia`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_mapbiomas = []\n",
    "\n",
    "#\n",
    "# Extract trajectory from WLTS\n",
    "#\n",
    "for point_row in samples_df.iterrows():\n",
    "    point_row = point_row[1]\n",
    "    \n",
    "    trajectories_mapbiomas.append(\n",
    "        service.tj(latitude  = point_row.geometry.y, \n",
    "                   longitude = point_row.geometry.x, \n",
    "                   start_date = 2018,\n",
    "                   end_date = 2018,\n",
    "                   collections = \"mapbiomas5_amazonia\").df()\n",
    "    )\n",
    "\n",
    "#\n",
    "# Create a Data Frame\n",
    "#\n",
    "trajectories_mapbiomas = pandas.concat(trajectories_mapbiomas).reset_index(drop=True)\n",
    "trajectories_mapbiomas[\"geometry\"] = samples_df[\"geometry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_mapbiomas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-amateur",
   "metadata": {},
   "source": [
    "# Prepare data to classification\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-stand",
   "metadata": {},
   "source": [
    "Now that each of the sample points' trajectories has been extracted, they will be used to train a linear classifier, which identifies water bodies in remotely sensed images.\n",
    "\n",
    "This section prepares the data for classification. In this process, all points identified as water have their path values converted to `1`, while all other values are represented by `0`. This allows the generation of a binary classifier, which determines where there is or is not water.\n",
    "\n",
    "This conversion is applied considering that there is one class that represents the Water element for each collection. The table below summarizes how each collection does this representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-julian",
   "metadata": {},
   "source": [
    "|         Collection        \t|      Nomenclature for water class   \t|\n",
    "|:-------------------------:\t|:----------------------------------:\t|\n",
    "|        IBGE (2018)        \t|      Corpo d'água Continental      \t|\n",
    "| MapBiomas Versão 5 (2018) \t|         Rio, Lago e Oceano         \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-columbus",
   "metadata": {},
   "source": [
    "Considering the information in the table, below each of the collections is prepared for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-correction",
   "metadata": {},
   "source": [
    "`IBGE Collection (2018)`\n",
    "\n",
    "> After running the command below, notice that the `class` column has its value summed to the values `0` and `1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_ibge.loc[trajectories_ibge[\"class\"] != \"Corpo d'água Continental\", \"class\"] = 0\n",
    "trajectories_ibge.loc[trajectories_ibge[\"class\"] == \"Corpo d'água Continental\", \"class\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_ibge.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-yellow",
   "metadata": {},
   "source": [
    "`MaBiomas Collection (2018)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_mapbiomas.loc[trajectories_mapbiomas[\"class\"] != \"Rio, Lago e Oceano\", \"class\"] = 0\n",
    "trajectories_mapbiomas.loc[trajectories_mapbiomas[\"class\"] == \"Rio, Lago e Oceano\", \"class\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_mapbiomas.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-latvia",
   "metadata": {},
   "source": [
    "# Select the training data\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-dressing",
   "metadata": {},
   "source": [
    "Before using the trajectories for training the linear classifier, it is essential to perform the agreement analysis to introduce no uncertainties into the model. To do this, the classes from both data sets are compared. Also, a confusion matrix is made to understand and quantify the points of agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_arr = confusion_matrix(trajectories_ibge[\"class\"].astype(\"int\"), trajectories_mapbiomas[\"class\"].astype(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi = 300)\n",
    "seaborn.heatmap(cm_arr, annot=True, fmt = 'g', cmap=\"YlGnBu\", cbar = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-canal",
   "metadata": {},
   "source": [
    "> Below, the samples are filtered considering the equality between both data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_matrix = trajectories_ibge[\"class\"].values == trajectories_mapbiomas[\"class\"].values\n",
    "\n",
    "trajectories_ibge_filtered = trajectories_ibge[true_matrix]\n",
    "trajectories_mapbiomas_filtered  = trajectories_mapbiomas[true_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_ibge_filtered.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-oasis",
   "metadata": {},
   "source": [
    "# Classifying\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-classics",
   "metadata": {},
   "source": [
    "In this section, the previously extracted and filtered samples will be used for training a linear classifier. After training, the model is applied. The classification process will be done considering a scene extracted from the Landsat-8/OLI data cube (temporal composition of 16 days and the pixel choice with less cloud influence done through the STACK algorithm).\n",
    "\n",
    "The defined study region is located within the Amazon biome, in a cube tile in Pará.\n",
    "\n",
    "> In this example, to reduce the computational requirements, a small region of the scene will be used, this one intersecting with the location of the grid points presented earlier. Furthermore, to facilitate classification, the **N**ormalized **D**ifference **W**ater **I**ndex (NDWI) is calculated.\n",
    "\n",
    "The command below loads the brick file containing the bands `3`, `5`, and `NDWI` (Already calculated earlier).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "brick = rasterio.open(\n",
    "    \"https://brazildatacube.dpi.inpe.br/public/workshop/bdc-2020-03/wlts/brick/2018/LC8_30_16D_STK_v001_043042_2018-06-10_2018-06-25_brick.tif\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-dispatch",
   "metadata": {},
   "source": [
    "The code below reprojects the grid points to the Coordinate Reference System (CRS) of the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_ibge_filtered = geopandas.GeoDataFrame(trajectories_ibge_filtered)\\\n",
    "                                .set_geometry(\"geometry\")\\\n",
    "                                .set_crs(\"EPSG:4326\")\n",
    "\n",
    "points = trajectories_ibge_filtered[\"geometry\"].to_crs(brick.crs)\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-collective",
   "metadata": {},
   "source": [
    "Now, we will train the linear classifier. \n",
    "\n",
    "> The [scikit-learn](https://scikit-learn.org/) library provides the classifier used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-check",
   "metadata": {},
   "source": [
    "Extract data for each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = list(\n",
    "    brick.sample((x, y) for x, y in zip(points.x, points.y))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-seventh",
   "metadata": {},
   "source": [
    "Training the linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier().fit(points, \n",
    "                            trajectories_ibge_filtered[\"class\"].astype(\"int\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-mobility",
   "metadata": {},
   "source": [
    "Classify the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "brick_array = brick.read()\n",
    "prediction_array = model.predict(brick_array.T.reshape((-1, 3)))\n",
    "\n",
    "prediction_array = prediction_array.reshape(brick_array.shape[2], brick_array.shape[1]).T.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-silly",
   "metadata": {},
   "source": [
    "Plot classified image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(prediction_array, cmap='GnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-designation",
   "metadata": {},
   "source": [
    "Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = brick.profile\n",
    "profile[\"dtype\"] = \"int16\"\n",
    "profile[\"count\"] = 1\n",
    "\n",
    "with rasterio.open(\"water-mask-classification.tif\", \"w\", **profile) as file:\n",
    "    file.write(prediction_array[numpy.newaxis, ...].astype('int16'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
